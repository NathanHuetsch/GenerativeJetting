{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78cafbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os, sys\n",
    "os.chdir(\"..\")\n",
    "from Source.Models.autoregGMM import AutoRegGMM\n",
    "from Source.Models.autoregBinned import AutoRegBinned\n",
    "from Source.Util.simulateToyData import ToySimulator\n",
    "from Source.Util.util import load_params, get, get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6217a6",
   "metadata": {},
   "source": [
    "# Ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29572e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpath = \"runs/paper_ramp2/\"\n",
    "params = load_params(runpath + \"paramfile.yaml\")\n",
    "params[\"device\"] = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1419ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AutoRegGMM hyperparameters: n_head=4, n_per_head=15, n_blocks=4, intermediate_fac=4, n_gauss=20\n",
      "Bayesianization hyperparameters: bayesian=3, prior_prec=1.0, iterations=50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoRegGMM(params)\n",
    "state_dict = torch.load(runpath+\"models/model_run0.pt\", map_location=params[\"device\"])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10eb5b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c6143e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ToySimulator(params).data\n",
    "data_split = params[\"data_split\"]\n",
    "n_data = len(data)\n",
    "cut1 = int(n_data - data_split[0])\n",
    "cut2 = int(n_data * (data_split[0] + data_split[1]))\n",
    "data_train = data[:cut1]\n",
    "data_test = data[cut2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c086e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py:167: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time estimate: 4.28 s = 0.07 min\n",
      "Sampling time estimate: 2.41 s = 0.04 min\n",
      "Sampling time estimate: 2.46 s = 0.04 min\n",
      "Sampling time estimate: 2.88 s = 0.05 min\n",
      "Sampling time estimate: 2.53 s = 0.04 min\n",
      "Sampling time estimate: 2.74 s = 0.05 min\n",
      "Sampling time estimate: 2.98 s = 0.05 min\n",
      "Sampling time estimate: 3.42 s = 0.06 min\n",
      "Sampling time estimate: 3.06 s = 0.05 min\n",
      "Sampling time estimate: 3.55 s = 0.06 min\n",
      "Sampling time estimate: 3.07 s = 0.05 min\n",
      "Sampling time estimate: 3.56 s = 0.06 min\n",
      "Sampling time estimate: 3.13 s = 0.05 min\n",
      "Sampling time estimate: 4.49 s = 0.07 min\n",
      "Sampling time estimate: 3.25 s = 0.05 min\n",
      "Sampling time estimate: 2.99 s = 0.05 min\n",
      "Sampling time estimate: 3.64 s = 0.06 min\n",
      "Sampling time estimate: 3.15 s = 0.05 min\n",
      "Sampling time estimate: 3.56 s = 0.06 min\n",
      "Sampling time estimate: 3.03 s = 0.05 min\n",
      "Sampling time estimate: 3.06 s = 0.05 min\n",
      "Sampling time estimate: 3.11 s = 0.05 min\n",
      "Sampling time estimate: 3.08 s = 0.05 min\n",
      "Sampling time estimate: 3.48 s = 0.06 min\n",
      "Sampling time estimate: 2.90 s = 0.05 min\n",
      "Sampling time estimate: 3.05 s = 0.05 min\n",
      "Sampling time estimate: 2.87 s = 0.05 min\n",
      "Sampling time estimate: 3.40 s = 0.06 min\n",
      "Sampling time estimate: 3.11 s = 0.05 min\n",
      "Sampling time estimate: 2.98 s = 0.05 min\n",
      "Sampling time estimate: 3.14 s = 0.05 min\n",
      "Sampling time estimate: 2.92 s = 0.05 min\n",
      "Sampling time estimate: 3.21 s = 0.05 min\n",
      "Sampling time estimate: 3.25 s = 0.05 min\n",
      "Sampling time estimate: 4.28 s = 0.07 min\n",
      "Sampling time estimate: 3.86 s = 0.06 min\n",
      "Sampling time estimate: 3.39 s = 0.06 min\n",
      "Sampling time estimate: 4.34 s = 0.07 min\n",
      "Sampling time estimate: 2.96 s = 0.05 min\n",
      "Sampling time estimate: 2.88 s = 0.05 min\n",
      "Sampling time estimate: 3.15 s = 0.05 min\n",
      "Sampling time estimate: 4.78 s = 0.08 min\n",
      "Sampling time estimate: 2.94 s = 0.05 min\n",
      "Sampling time estimate: 3.22 s = 0.05 min\n",
      "Sampling time estimate: 2.92 s = 0.05 min\n",
      "Sampling time estimate: 2.99 s = 0.05 min\n",
      "Sampling time estimate: 3.05 s = 0.05 min\n",
      "Sampling time estimate: 4.06 s = 0.07 min\n",
      "Sampling time estimate: 3.09 s = 0.05 min\n",
      "Sampling time estimate: 3.67 s = 0.06 min\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "nBNN = 50\n",
    "data_predict = np.zeros((0, data_train.shape[1]))\n",
    "for i in range(nBNN):\n",
    "    data_predict = np.append(data_predict, model.sample_n(n_samples), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52de02",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc1bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paper(out, obs_train, obs_test, obs_predict, name, bins=60, weight_samples=1, \n",
    "               predict_weights=None, unit=None, range=None, ymaxAbs=1., ymaxRel=1.):\n",
    "    with PdfPages(out) as pp:\n",
    "        y_t,  bins = np.histogram(obs_test, bins=bins, range=range)\n",
    "        y_tr, _ = np.histogram(obs_train, bins=bins)\n",
    "\n",
    "        if weight_samples == 1:\n",
    "            y_g,  _ = np.histogram(obs_predict, bins=bins, weights=predict_weights)\n",
    "            hists = [y_t, y_g, y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.sqrt(y_g), np.sqrt(y_tr)]\n",
    "        else:\n",
    "            obs_predict = obs_predict.reshape(weight_samples,\n",
    "                    len(obs_predict)//weight_samples)\n",
    "            hist_weights = (weight_samples*[None] if predict_weights is None\n",
    "                            else predict_weights.reshape(obs_predict.shape))\n",
    "            hists_g = np.array([np.histogram(obs_predict[i,:], bins=bins,\n",
    "                                             weights=hist_weights[i])[0]\n",
    "                                for i in np.arange(weight_samples)])\n",
    "            hists = [y_t, np.mean(hists_g, axis=0), y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.std(hists_g, axis=0), np.sqrt(y_tr)]\n",
    "        integrals = [np.sum((bins[1:] - bins[:-1]) * y) for y in hists]\n",
    "        scales = [1 / integral if integral != 0. else 1. for integral in integrals]\n",
    "            \n",
    "        FONTSIZE = 14\n",
    "        labels = [\"True\", \"Model\", \"Train\"]\n",
    "        colors = [\"#e41a1c\", \"#3b528b\", \"#1a8507\"]\n",
    "        dup_last = lambda a: np.append(a, a[-1])\n",
    "\n",
    "        fig1, axs = plt.subplots(3, 1, sharex=True,\n",
    "                gridspec_kw={\"height_ratios\" : [4, 1, 1], \"hspace\" : 0.00})\n",
    "        fig1.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        for y, y_err, scale, label, color in zip(hists, hist_errors, scales,\n",
    "                                            labels, colors):\n",
    "\n",
    "            axs[0].step(bins, dup_last(y) * scale, label=label, color=color,\n",
    "                    linewidth=1.0, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y + y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y - y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].fill_between(bins, dup_last(y - y_err) * scale,\n",
    "                    dup_last(y + y_err) * scale, facecolor=color,\n",
    "                    alpha=0.3, step=\"post\")\n",
    "\n",
    "            if label == \"True\": continue\n",
    "\n",
    "            ratio = (y * scale)/ (hists[0] * scales[0])\n",
    "            ratio_err = np.sqrt((y_err / y)**2 + (hist_errors[0] / hists[0])**2)\n",
    "            ratio_isnan = np.isnan(ratio)\n",
    "            ratio[ratio_isnan] = 1.\n",
    "            ratio_err[ratio_isnan] = 0.\n",
    "\n",
    "            axs[1].step(bins, dup_last(ratio), linewidth=1.0, where=\"post\", color=color)\n",
    "            axs[1].step(bins, dup_last(ratio + ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].step(bins, dup_last(ratio - ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].fill_between(bins, dup_last(ratio - ratio_err),\n",
    "                    dup_last(ratio + ratio_err), facecolor=color, alpha=0.3, step=\"post\")\n",
    "\n",
    "            delta = np.fabs(ratio - 1) * 100\n",
    "            delta_err = ratio_err * 100\n",
    "\n",
    "            markers, caps, bars = axs[2].errorbar((bins[:-1] + bins[1:])/2, delta,\n",
    "                    yerr=delta_err, ecolor=color, color=color, elinewidth=0.5,\n",
    "                    linewidth=0, fmt=\".\", capsize=2)\n",
    "            [cap.set_alpha(0.5) for cap in caps]\n",
    "            [bar.set_alpha(0.5) for bar in bars]\n",
    "\n",
    "\n",
    "        axs[0].legend(loc=\"upper left\", frameon=False, fontsize=FONTSIZE)\n",
    "        axs[0].set_ylabel(\"Normalized\", fontsize = FONTSIZE)\n",
    "\n",
    "        axs[1].set_ylabel(r\"$\\frac{\\mathrm{Model}}{\\mathrm{True}}$\",\n",
    "                fontsize = FONTSIZE)\n",
    "        axs[1].set_yticks([0.95,1,1.05])\n",
    "        axs[1].set_ylim([0.9,1.1])\n",
    "        axs[1].axhline(y=1, c=\"black\", ls=\"--\", lw=0.7)\n",
    "        axs[1].axhline(y=1.2, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        axs[1].axhline(y=0.8, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        plt.xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "\n",
    "        axs[2].set_ylim((0.05,20))\n",
    "        axs[2].set_yscale(\"log\")\n",
    "        axs[2].set_yticks([0.1, 1.0, 10.0])\n",
    "        axs[2].set_yticklabels([r\"$0.1$\", r\"$1.0$\", \"$10.0$\"])\n",
    "        axs[2].set_yticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                            2., 3., 4., 5., 6., 7., 8., 9.], minor=True)\n",
    "\n",
    "        axs[2].axhline(y=1.0,linewidth=0.5, linestyle=\"--\", color=\"grey\")\n",
    "        axs[2].axhspan(0, 1.0, facecolor=\"#cccccc\", alpha=0.3)\n",
    "        axs[2].set_ylabel(r\"$\\delta [\\%]$\", fontsize = FONTSIZE)\n",
    "\n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig2, axs = plt.subplots(1, 1)\n",
    "        fig2.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Absolute uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] * scales[1]), color=colors[1])\n",
    "        axs.set_ylim(0., ymaxAbs)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig3, axs = plt.subplots(1, 1)\n",
    "        fig3.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Relative uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] / hists[1]), color=colors[1])\n",
    "        axs.set_ylim(0., ymaxRel)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e378c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_paper(\"Scripts/paper/GMMramp.pdf\", data_train[:,1], data_test[:,1], data_predict[:,1], \n",
    "           \"x_1\", weight_samples=nBNN, ymaxAbs=.1, ymaxRel=.1, range=[.1, .9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5af5a4",
   "metadata": {},
   "source": [
    "## Plot with likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6681b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = .1, .9\n",
    "prec = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1113d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMargLikelihoodnDim(model, xmin, xmax, dim, prec=1000):\n",
    "    xs = torch.linspace(xmin, xmax, prec)\n",
    "    idx = model.n_jets * torch.ones(prec, 2, dtype=torch.int).float()\n",
    "    idx[:,1] = xs\n",
    "    \n",
    "    mu, sigma, weights = model.net(idx) #indices: batch, component, gauss\n",
    "    mix = D.Categorical(weights)\n",
    "    comp = D.Normal(mu, sigma)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    \n",
    "    probs = torch.zeros(prec, prec, dtype=torch.float) #likelihood array\n",
    "    for ix in range(prec):\n",
    "        base = torch.zeros(prec, 2)\n",
    "        base[:,0] = xs[ix]\n",
    "        base[:,1] = xs\n",
    "        probs[ix,:] = torch.exp(torch.sum(gmm.log_prob(base), axis=-1))\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    xs = xs.detach().cpu().numpy()\n",
    "    \n",
    "    marg = np.trapz(probs, x=xs, axis=dim)\n",
    "    norm = np.trapz(marg, x=xs)\n",
    "    #print(f\"Normalization: {norm:.5f}\")\n",
    "    marg /= norm\n",
    "    \n",
    "    return xs, marg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcb26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.zeros(prec)\n",
    "margL = np.zeros((prec, nBNN))\n",
    "#model.train_loader = DataLoader(dataset=data[:cut1], batch_size=params[\"batch_size\"], shuffle=True)\n",
    "for j in range(nBNN):\n",
    "    if model.net.bayesian >= 1:\n",
    "        model.net.map = get(model.params, \"fix_mu\", False)\n",
    "        for i in range(model.net.n_blocks):\n",
    "            model.net.transformer.h[i].mlp.c_fc.random = None\n",
    "            model.net.transformer.h[i].mlp.c_proj.random = None\n",
    "    if model.net.bayesian >= 2:\n",
    "        for i in range(model.net.n_blocks):\n",
    "            model.net.transformer.h[i].attn.c_attn.random = None\n",
    "            model.net.transformer.h[i].attn.c_proj.random = None\n",
    "    if model.net.bayesian >= 3:\n",
    "        model.net.transformer.wte.random = None\n",
    "        model.net.lm_head.random = None\n",
    "    xs, margL[:,j] = getMargLikelihoodnDim(model, xmin, xmax, 0, prec=prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f45200",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanMargL = np.mean(margL, axis=1)\n",
    "stdMargL = np.std(margL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161dd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paper_likelihoods(out, obs_train, obs_test, obs_predict, name, bins=60, weight_samples=1, \n",
    "               predict_weights=None, unit=None, range=None, ymaxAbs=1., ymaxRel=1.):\n",
    "    with PdfPages(out) as pp:\n",
    "        y_t,  bins = np.histogram(obs_test, bins=bins, range=range)\n",
    "        y_tr, _ = np.histogram(obs_train, bins=bins)\n",
    "\n",
    "        if weight_samples == 1:\n",
    "            y_g,  _ = np.histogram(obs_predict, bins=bins, weights=predict_weights)\n",
    "            hists = [y_t, y_g, y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.sqrt(y_g), np.sqrt(y_tr)]\n",
    "        else:\n",
    "            obs_predict = obs_predict.reshape(weight_samples,\n",
    "                    len(obs_predict)//weight_samples)\n",
    "            hist_weights = (weight_samples*[None] if predict_weights is None\n",
    "                            else predict_weights.reshape(obs_predict.shape))\n",
    "            hists_g = np.array([np.histogram(obs_predict[i,:], bins=bins,\n",
    "                                             weights=hist_weights[i])[0]\n",
    "                                for i in np.arange(weight_samples)])\n",
    "            hists = [y_t, np.mean(hists_g, axis=0), y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.std(hists_g, axis=0), np.sqrt(y_tr)]\n",
    "        integrals = [np.sum((bins[1:] - bins[:-1]) * y) for y in hists]\n",
    "        scales = [1 / integral if integral != 0. else 1. for integral in integrals]\n",
    "            \n",
    "        FONTSIZE = 14\n",
    "        labels = [\"True\", \"Model\", \"Train\"]\n",
    "        colors = [\"#e41a1c\", \"#3b528b\", \"#1a8507\"]\n",
    "        dup_last = lambda a: np.append(a, a[-1])\n",
    "\n",
    "        fig1, axs = plt.subplots(3, 1, sharex=True,\n",
    "                gridspec_kw={\"height_ratios\" : [4, 1, 1], \"hspace\" : 0.00})\n",
    "        fig1.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        for y, y_err, scale, label, color in zip(hists, hist_errors, scales,\n",
    "                                            labels, colors):\n",
    "\n",
    "            axs[0].step(bins, dup_last(y) * scale, label=label, color=color,\n",
    "                    linewidth=1.0, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y + y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y - y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].fill_between(bins, dup_last(y - y_err) * scale,\n",
    "                    dup_last(y + y_err) * scale, facecolor=color,\n",
    "                    alpha=0.3, step=\"post\")\n",
    "\n",
    "            if label == \"True\": continue\n",
    "\n",
    "            ratio = (y * scale)/ (hists[0] * scales[0])\n",
    "            ratio_err = np.sqrt((y_err / y)**2 + (hist_errors[0] / hists[0])**2)\n",
    "            ratio_isnan = np.isnan(ratio)\n",
    "            ratio[ratio_isnan] = 1.\n",
    "            ratio_err[ratio_isnan] = 0.\n",
    "\n",
    "            axs[1].step(bins, dup_last(ratio), linewidth=1.0, where=\"post\", color=color)\n",
    "            axs[1].step(bins, dup_last(ratio + ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].step(bins, dup_last(ratio - ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].fill_between(bins, dup_last(ratio - ratio_err),\n",
    "                    dup_last(ratio + ratio_err), facecolor=color, alpha=0.3, step=\"post\")\n",
    "\n",
    "            delta = np.fabs(ratio - 1) * 100\n",
    "            delta_err = ratio_err * 100\n",
    "\n",
    "            markers, caps, bars = axs[2].errorbar((bins[:-1] + bins[1:])/2, delta,\n",
    "                    yerr=delta_err, ecolor=color, color=color, elinewidth=0.5,\n",
    "                    linewidth=0, fmt=\".\", capsize=2)\n",
    "            [cap.set_alpha(0.5) for cap in caps]\n",
    "            [bar.set_alpha(0.5) for bar in bars]\n",
    "\n",
    "\n",
    "        axs[0].fill_between(xs, meanMargL + stdMargL, meanMargL - stdMargL,\n",
    "                           facecolor=colors[1], alpha=.3)\n",
    "        axs[0].legend(loc=\"upper left\", frameon=False, fontsize=FONTSIZE)\n",
    "        axs[0].set_ylabel(\"Normalized\", fontsize = FONTSIZE)\n",
    "\n",
    "        axs[1].set_ylabel(r\"$\\frac{\\mathrm{Model}}{\\mathrm{True}}$\",\n",
    "                fontsize = FONTSIZE)\n",
    "        axs[1].set_yticks([0.95,1,1.05])\n",
    "        axs[1].set_ylim([0.9,1.1])\n",
    "        axs[1].axhline(y=1, c=\"black\", ls=\"--\", lw=0.7)\n",
    "        axs[1].axhline(y=1.2, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        axs[1].axhline(y=0.8, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        plt.xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "\n",
    "        axs[2].set_ylim((0.05,20))\n",
    "        axs[2].set_yscale(\"log\")\n",
    "        axs[2].set_yticks([0.1, 1.0, 10.0])\n",
    "        axs[2].set_yticklabels([r\"$0.1$\", r\"$1.0$\", \"$10.0$\"])\n",
    "        axs[2].set_yticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                            2., 3., 4., 5., 6., 7., 8., 9.], minor=True)\n",
    "\n",
    "        axs[2].axhline(y=1.0,linewidth=0.5, linestyle=\"--\", color=\"grey\")\n",
    "        axs[2].axhspan(0, 1.0, facecolor=\"#cccccc\", alpha=0.3)\n",
    "        axs[2].set_ylabel(r\"$\\delta [\\%]$\", fontsize = FONTSIZE)\n",
    "\n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig2, axs = plt.subplots(1, 1)\n",
    "        fig2.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Absolute uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] * scales[1]), color=colors[1])\n",
    "        axs.plot(xs, stdMargL, color=colors[1])\n",
    "        axs.set_ylim(0., ymaxAbs)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig3, axs = plt.subplots(1, 1)\n",
    "        fig3.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Relative uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] / hists[1]), color=colors[1])\n",
    "        axs.plot(xs, stdMargL / meanMargL, color=colors[1])\n",
    "        axs.set_ylim(0., ymaxRel)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf5ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_paper_likelihoods(\"Scripts/paper/GMMramp_likelihoods.pdf\", data_train[:,1], \n",
    "            data_test[:,1], data_predict[:,1], \"x_1\", weight_samples=nBNN, \n",
    "            ymaxAbs=.1, ymaxRel=.1, range=[.1, .9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef084da3",
   "metadata": {},
   "source": [
    "# Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65bf0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpath = \"runs/paper_sphere2/\"\n",
    "params = load_params(runpath + \"paramfile.yaml\")\n",
    "params[\"device\"] = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57d0769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AutoRegGMM hyperparameters: n_head=4, n_per_head=15, n_blocks=4, intermediate_fac=4, n_gauss=20\n",
      "Bayesianization hyperparameters: bayesian=3, prior_prec=1.0, iterations=50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoRegGMM(params)\n",
    "state_dict = torch.load(runpath+\"models/model_run0.pt\", map_location=params[\"device\"])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b35f90",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27aba2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ToySimulator(params).data\n",
    "data_split = params[\"data_split\"]\n",
    "n_data = len(data)\n",
    "cut1 = int(n_data - data_split[0])\n",
    "cut2 = int(n_data * (data_split[0] + data_split[1]))\n",
    "data_train = data[:cut1]\n",
    "data_test = data[cut2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "937d8b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py:167: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time estimate: 3.22 s = 0.05 min\n",
      "Sampling time estimate: 3.11 s = 0.05 min\n",
      "Sampling time estimate: 2.97 s = 0.05 min\n",
      "Sampling time estimate: 3.40 s = 0.06 min\n",
      "Sampling time estimate: 3.03 s = 0.05 min\n",
      "Sampling time estimate: 2.46 s = 0.04 min\n",
      "Sampling time estimate: 2.64 s = 0.04 min\n",
      "Sampling time estimate: 3.39 s = 0.06 min\n",
      "Sampling time estimate: 3.06 s = 0.05 min\n",
      "Sampling time estimate: 3.28 s = 0.05 min\n",
      "Sampling time estimate: 3.64 s = 0.06 min\n",
      "Sampling time estimate: 2.99 s = 0.05 min\n",
      "Sampling time estimate: 3.10 s = 0.05 min\n",
      "Sampling time estimate: 3.14 s = 0.05 min\n",
      "Sampling time estimate: 3.36 s = 0.06 min\n",
      "Sampling time estimate: 3.22 s = 0.05 min\n",
      "Sampling time estimate: 3.56 s = 0.06 min\n",
      "Sampling time estimate: 2.87 s = 0.05 min\n",
      "Sampling time estimate: 4.02 s = 0.07 min\n",
      "Sampling time estimate: 4.02 s = 0.07 min\n",
      "Sampling time estimate: 3.10 s = 0.05 min\n",
      "Sampling time estimate: 3.99 s = 0.07 min\n",
      "Sampling time estimate: 2.95 s = 0.05 min\n",
      "Sampling time estimate: 3.40 s = 0.06 min\n",
      "Sampling time estimate: 3.09 s = 0.05 min\n",
      "Sampling time estimate: 3.78 s = 0.06 min\n",
      "Sampling time estimate: 3.89 s = 0.06 min\n",
      "Sampling time estimate: 3.03 s = 0.05 min\n",
      "Sampling time estimate: 3.26 s = 0.05 min\n",
      "Sampling time estimate: 2.88 s = 0.05 min\n",
      "Sampling time estimate: 2.92 s = 0.05 min\n",
      "Sampling time estimate: 4.17 s = 0.07 min\n",
      "Sampling time estimate: 3.88 s = 0.06 min\n",
      "Sampling time estimate: 2.95 s = 0.05 min\n",
      "Sampling time estimate: 2.97 s = 0.05 min\n",
      "Sampling time estimate: 2.90 s = 0.05 min\n",
      "Sampling time estimate: 3.33 s = 0.06 min\n",
      "Sampling time estimate: 2.97 s = 0.05 min\n",
      "Sampling time estimate: 3.82 s = 0.06 min\n",
      "Sampling time estimate: 3.39 s = 0.06 min\n",
      "Sampling time estimate: 2.95 s = 0.05 min\n",
      "Sampling time estimate: 3.49 s = 0.06 min\n",
      "Sampling time estimate: 4.10 s = 0.07 min\n",
      "Sampling time estimate: 2.98 s = 0.05 min\n",
      "Sampling time estimate: 2.99 s = 0.05 min\n",
      "Sampling time estimate: 3.19 s = 0.05 min\n",
      "Sampling time estimate: 2.95 s = 0.05 min\n",
      "Sampling time estimate: 2.89 s = 0.05 min\n",
      "Sampling time estimate: 2.93 s = 0.05 min\n",
      "Sampling time estimate: 2.94 s = 0.05 min\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "nBNN = 50\n",
    "data_predict = np.zeros((0, data_train.shape[1]))\n",
    "for i in range(nBNN):\n",
    "    data_predict = np.append(data_predict, model.sample_n(n_samples), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19996cf",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00ce309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paper(out, obs_train, obs_test, obs_predict, name, bins=60, weight_samples=1, \n",
    "               predict_weights=None, unit=None, range=None, ymaxAbs=1., ymaxRel=1.):\n",
    "    with PdfPages(out) as pp:\n",
    "        y_t,  bins = np.histogram(obs_test, bins=bins, range=range)\n",
    "        y_tr, _ = np.histogram(obs_train, bins=bins)\n",
    "\n",
    "        if weight_samples == 1:\n",
    "            y_g,  _ = np.histogram(obs_predict, bins=bins, weights=predict_weights)\n",
    "            hists = [y_t, y_g, y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.sqrt(y_g), np.sqrt(y_tr)]\n",
    "        else:\n",
    "            obs_predict = obs_predict.reshape(weight_samples,\n",
    "                    len(obs_predict)//weight_samples)\n",
    "            hist_weights = (weight_samples*[None] if predict_weights is None\n",
    "                            else predict_weights.reshape(obs_predict.shape))\n",
    "            hists_g = np.array([np.histogram(obs_predict[i,:], bins=bins,\n",
    "                                             weights=hist_weights[i])[0]\n",
    "                                for i in np.arange(weight_samples)])\n",
    "            hists = [y_t, np.mean(hists_g, axis=0), y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.std(hists_g, axis=0), np.sqrt(y_tr)]\n",
    "        integrals = [np.sum((bins[1:] - bins[:-1]) * y) for y in hists]\n",
    "        scales = [1 / integral if integral != 0. else 1. for integral in integrals]\n",
    "            \n",
    "        FONTSIZE = 14\n",
    "        labels = [\"True\", \"Model\", \"Train\"]\n",
    "        colors = [\"#e41a1c\", \"#3b528b\", \"#1a8507\"]\n",
    "        dup_last = lambda a: np.append(a, a[-1])\n",
    "\n",
    "        fig1, axs = plt.subplots(3, 1, sharex=True,\n",
    "                gridspec_kw={\"height_ratios\" : [4, 1, 1], \"hspace\" : 0.00})\n",
    "        fig1.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        for y, y_err, scale, label, color in zip(hists, hist_errors, scales,\n",
    "                                            labels, colors):\n",
    "\n",
    "            axs[0].step(bins, dup_last(y) * scale, label=label, color=color,\n",
    "                    linewidth=1.0, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y + y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y - y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].fill_between(bins, dup_last(y - y_err) * scale,\n",
    "                    dup_last(y + y_err) * scale, facecolor=color,\n",
    "                    alpha=0.3, step=\"post\")\n",
    "\n",
    "            if label == \"True\": continue\n",
    "\n",
    "            ratio = (y * scale)/ (hists[0] * scales[0])\n",
    "            ratio_err = np.sqrt((y_err / y)**2 + (hist_errors[0] / hists[0])**2)\n",
    "            ratio_isnan = np.isnan(ratio)\n",
    "            ratio[ratio_isnan] = 1.\n",
    "            ratio_err[ratio_isnan] = 0.\n",
    "\n",
    "            axs[1].step(bins, dup_last(ratio), linewidth=1.0, where=\"post\", color=color)\n",
    "            axs[1].step(bins, dup_last(ratio + ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].step(bins, dup_last(ratio - ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].fill_between(bins, dup_last(ratio - ratio_err),\n",
    "                    dup_last(ratio + ratio_err), facecolor=color, alpha=0.3, step=\"post\")\n",
    "\n",
    "            delta = np.fabs(ratio - 1) * 100\n",
    "            delta_err = ratio_err * 100\n",
    "\n",
    "            markers, caps, bars = axs[2].errorbar((bins[:-1] + bins[1:])/2, delta,\n",
    "                    yerr=delta_err, ecolor=color, color=color, elinewidth=0.5,\n",
    "                    linewidth=0, fmt=\".\", capsize=2)\n",
    "            [cap.set_alpha(0.5) for cap in caps]\n",
    "            [bar.set_alpha(0.5) for bar in bars]\n",
    "\n",
    "\n",
    "        axs[0].legend(loc=\"upper left\", frameon=False, fontsize=FONTSIZE)\n",
    "        axs[0].set_ylabel(\"Normalized\", fontsize = FONTSIZE)\n",
    "\n",
    "        axs[1].set_ylabel(r\"$\\frac{\\mathrm{Model}}{\\mathrm{True}}$\",\n",
    "                fontsize = FONTSIZE)\n",
    "        axs[1].set_yticks([0.95,1,1.05])\n",
    "        axs[1].set_ylim([0.9,1.1])\n",
    "        axs[1].axhline(y=1, c=\"black\", ls=\"--\", lw=0.7)\n",
    "        axs[1].axhline(y=1.2, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        axs[1].axhline(y=0.8, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        plt.xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "\n",
    "        axs[2].set_ylim((0.05,20))\n",
    "        axs[2].set_yscale(\"log\")\n",
    "        axs[2].set_yticks([0.1, 1.0, 10.0])\n",
    "        axs[2].set_yticklabels([r\"$0.1$\", r\"$1.0$\", \"$10.0$\"])\n",
    "        axs[2].set_yticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                            2., 3., 4., 5., 6., 7., 8., 9.], minor=True)\n",
    "\n",
    "        axs[2].axhline(y=1.0,linewidth=0.5, linestyle=\"--\", color=\"grey\")\n",
    "        axs[2].axhspan(0, 1.0, facecolor=\"#cccccc\", alpha=0.3)\n",
    "        axs[2].set_ylabel(r\"$\\delta [\\%]$\", fontsize = FONTSIZE)\n",
    "\n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig2, axs = plt.subplots(1, 1)\n",
    "        fig2.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Absolute uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] * scales[1]), color=colors[1])\n",
    "        axs.set_ylim(0., ymaxAbs)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig3, axs = plt.subplots(1, 1)\n",
    "        fig3.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Relative uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] / hists[1]), color=colors[1])\n",
    "        axs.set_ylim(0., ymaxRel)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009df314",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train, _ = ToySimulator.getSpherical(data_train)\n",
    "R_test, _ = ToySimulator.getSpherical(data_test)\n",
    "R_predict, _= ToySimulator.getSpherical(data_predict)\n",
    "plot_paper(\"Scripts/paper/GMMsphere.pdf\", R_train, R_test, R_predict, \n",
    "           \"x_1\", weight_samples=nBNN, ymaxAbs=.03, ymaxRel=.1, range=[-1.5, 1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d90d78",
   "metadata": {},
   "source": [
    "## Plot with likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a943b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -1.5, 1.5\n",
    "prec = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59ce4223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMargLikelihoodnDim(model, xmin, xmax, dim, prec=1000):\n",
    "    xs = torch.linspace(xmin, xmax, prec)\n",
    "    idx = model.n_jets * torch.ones(prec, 2, dtype=torch.int).float()\n",
    "    idx[:,1] = xs\n",
    "    \n",
    "    mu, sigma, weights = model.net(idx) #indices: batch, component, gauss\n",
    "    mix = D.Categorical(weights)\n",
    "    comp = D.Normal(mu, sigma)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    \n",
    "    probs = torch.zeros(prec, prec, dtype=torch.float) #likelihood array\n",
    "    for ix in range(prec):\n",
    "        base = torch.zeros(prec, 2)\n",
    "        base[:,0] = xs[ix]\n",
    "        base[:,1] = xs\n",
    "        probs[ix,:] = torch.exp(torch.sum(gmm.log_prob(base), axis=-1))\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    xs = xs.detach().cpu().numpy()\n",
    "    \n",
    "    marg = np.trapz(probs, x=xs, axis=dim)\n",
    "    norm = np.trapz(marg, x=xs)\n",
    "    #print(f\"Normalization: {norm:.5f}\")\n",
    "    marg /= norm\n",
    "    \n",
    "    return xs, marg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30303b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.zeros(prec)\n",
    "margL = np.zeros((prec, nBNN))\n",
    "#model.train_loader = DataLoader(dataset=data[:cut1], batch_size=params[\"batch_size\"], shuffle=True)\n",
    "for j in range(nBNN):\n",
    "    if model.net.bayesian >= 1:\n",
    "        model.net.map = get(model.params, \"fix_mu\", False)\n",
    "        for i in range(model.net.n_blocks):\n",
    "            model.net.transformer.h[i].mlp.c_fc.random = None\n",
    "            model.net.transformer.h[i].mlp.c_proj.random = None\n",
    "    if model.net.bayesian >= 2:\n",
    "        for i in range(model.net.n_blocks):\n",
    "            model.net.transformer.h[i].attn.c_attn.random = None\n",
    "            model.net.transformer.h[i].attn.c_proj.random = None\n",
    "    if model.net.bayesian >= 3:\n",
    "        model.net.transformer.wte.random = None\n",
    "        model.net.lm_head.random = None\n",
    "    xs, margL[:,j] = getMargLikelihoodnDim(model, xmin, xmax, 0, prec=prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbfb0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanMargL = np.mean(margL, axis=1)\n",
    "stdMargL = np.std(margL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f384e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_paper_likelihoods(out, obs_train, obs_test, obs_predict, name, bins=60, weight_samples=1, \n",
    "               predict_weights=None, unit=None, range=None, ymaxAbs=1., ymaxRel=1.):\n",
    "    with PdfPages(out) as pp:\n",
    "        y_t,  bins = np.histogram(obs_test, bins=bins, range=range)\n",
    "        y_tr, _ = np.histogram(obs_train, bins=bins)\n",
    "\n",
    "        if weight_samples == 1:\n",
    "            y_g,  _ = np.histogram(obs_predict, bins=bins, weights=predict_weights)\n",
    "            hists = [y_t, y_g, y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.sqrt(y_g), np.sqrt(y_tr)]\n",
    "        else:\n",
    "            obs_predict = obs_predict.reshape(weight_samples,\n",
    "                    len(obs_predict)//weight_samples)\n",
    "            hist_weights = (weight_samples*[None] if predict_weights is None\n",
    "                            else predict_weights.reshape(obs_predict.shape))\n",
    "            hists_g = np.array([np.histogram(obs_predict[i,:], bins=bins,\n",
    "                                             weights=hist_weights[i])[0]\n",
    "                                for i in np.arange(weight_samples)])\n",
    "            hists = [y_t, np.mean(hists_g, axis=0), y_tr]\n",
    "            hist_errors = [np.sqrt(y_t), np.std(hists_g, axis=0), np.sqrt(y_tr)]\n",
    "        integrals = [np.sum((bins[1:] - bins[:-1]) * y) for y in hists]\n",
    "        scales = [1 / integral if integral != 0. else 1. for integral in integrals]\n",
    "            \n",
    "        FONTSIZE = 14\n",
    "        labels = [\"True\", \"Model\", \"Train\"]\n",
    "        colors = [\"#e41a1c\", \"#3b528b\", \"#1a8507\"]\n",
    "        dup_last = lambda a: np.append(a, a[-1])\n",
    "\n",
    "        fig1, axs = plt.subplots(3, 1, sharex=True,\n",
    "                gridspec_kw={\"height_ratios\" : [4, 1, 1], \"hspace\" : 0.00})\n",
    "        fig1.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        for y, y_err, scale, label, color in zip(hists, hist_errors, scales,\n",
    "                                            labels, colors):\n",
    "\n",
    "            axs[0].step(bins, dup_last(y) * scale, label=label, color=color,\n",
    "                    linewidth=1.0, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y + y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].step(bins, dup_last(y - y_err) * scale, color=color,\n",
    "                    alpha=0.5, linewidth=0.5, where=\"post\")\n",
    "            axs[0].fill_between(bins, dup_last(y - y_err) * scale,\n",
    "                    dup_last(y + y_err) * scale, facecolor=color,\n",
    "                    alpha=0.3, step=\"post\")\n",
    "\n",
    "            if label == \"True\": continue\n",
    "\n",
    "            ratio = (y * scale)/ (hists[0] * scales[0])\n",
    "            ratio_err = np.sqrt((y_err / y)**2 + (hist_errors[0] / hists[0])**2)\n",
    "            ratio_isnan = np.isnan(ratio)\n",
    "            ratio[ratio_isnan] = 1.\n",
    "            ratio_err[ratio_isnan] = 0.\n",
    "\n",
    "            axs[1].step(bins, dup_last(ratio), linewidth=1.0, where=\"post\", color=color)\n",
    "            axs[1].step(bins, dup_last(ratio + ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].step(bins, dup_last(ratio - ratio_err), color=color, alpha=0.5,\n",
    "                    linewidth=0.5, where=\"post\")\n",
    "            axs[1].fill_between(bins, dup_last(ratio - ratio_err),\n",
    "                    dup_last(ratio + ratio_err), facecolor=color, alpha=0.3, step=\"post\")\n",
    "\n",
    "            delta = np.fabs(ratio - 1) * 100\n",
    "            delta_err = ratio_err * 100\n",
    "\n",
    "            markers, caps, bars = axs[2].errorbar((bins[:-1] + bins[1:])/2, delta,\n",
    "                    yerr=delta_err, ecolor=color, color=color, elinewidth=0.5,\n",
    "                    linewidth=0, fmt=\".\", capsize=2)\n",
    "            [cap.set_alpha(0.5) for cap in caps]\n",
    "            [bar.set_alpha(0.5) for bar in bars]\n",
    "\n",
    "\n",
    "        axs[0].fill_between(xs, meanMargL + stdMargL, meanMargL - stdMargL,\n",
    "                           facecolor=colors[1], alpha=.3)\n",
    "        axs[0].legend(loc=\"upper left\", frameon=False, fontsize=FONTSIZE)\n",
    "        axs[0].set_ylabel(\"Normalized\", fontsize = FONTSIZE)\n",
    "\n",
    "        axs[1].set_ylabel(r\"$\\frac{\\mathrm{Model}}{\\mathrm{True}}$\",\n",
    "                fontsize = FONTSIZE)\n",
    "        axs[1].set_yticks([0.95,1,1.05])\n",
    "        axs[1].set_ylim([0.9,1.1])\n",
    "        axs[1].axhline(y=1, c=\"black\", ls=\"--\", lw=0.7)\n",
    "        axs[1].axhline(y=1.2, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        axs[1].axhline(y=0.8, c=\"black\", ls=\"dotted\", lw=0.5)\n",
    "        plt.xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "\n",
    "        axs[2].set_ylim((0.05,20))\n",
    "        axs[2].set_yscale(\"log\")\n",
    "        axs[2].set_yticks([0.1, 1.0, 10.0])\n",
    "        axs[2].set_yticklabels([r\"$0.1$\", r\"$1.0$\", \"$10.0$\"])\n",
    "        axs[2].set_yticks([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                            2., 3., 4., 5., 6., 7., 8., 9.], minor=True)\n",
    "\n",
    "        axs[2].axhline(y=1.0,linewidth=0.5, linestyle=\"--\", color=\"grey\")\n",
    "        axs[2].axhspan(0, 1.0, facecolor=\"#cccccc\", alpha=0.3)\n",
    "        axs[2].set_ylabel(r\"$\\delta [\\%]$\", fontsize = FONTSIZE)\n",
    "\n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig2, axs = plt.subplots(1, 1)\n",
    "        fig2.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Absolute uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] * scales[1]), color=colors[1])\n",
    "        axs.plot(xs, stdMargL, color=colors[1])\n",
    "        axs.set_ylim(0., ymaxAbs)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()\n",
    "        \n",
    "        fig3, axs = plt.subplots(1, 1)\n",
    "        fig3.tight_layout(pad=0.0, w_pad=0.0, h_pad=0.0, rect=(0.07,0.06,0.99,0.95))\n",
    "        \n",
    "        axs.set_ylabel(\"Relative uncertainty\", fontsize = FONTSIZE)\n",
    "        axs.set_xlabel(r\"${%s}$ %s\" % (name, (\"\" if unit is None else f\"[{unit}]\")),\n",
    "                fontsize = FONTSIZE)\n",
    "        \n",
    "        axs.step(bins, dup_last(hist_errors[1] / hists[1]), color=colors[1])\n",
    "        axs.plot(xs, stdMargL / meanMargL, color=colors[1])\n",
    "        axs.set_ylim(0., ymaxRel)\n",
    "            \n",
    "        plt.savefig(pp, format=\"pdf\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b650a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22053/1493763218.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio = (y * scale)/ (hists[0] * scales[0])\n",
      "/tmp/ipykernel_22053/1493763218.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio_err = np.sqrt((y_err / y)**2 + (hist_errors[0] / hists[0])**2)\n",
      "/tmp/ipykernel_22053/1493763218.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio = (y * scale)/ (hists[0] * scales[0])\n"
     ]
    }
   ],
   "source": [
    "plot_paper_likelihoods(\"Scripts/paper/GMMsphere_likelihoods.pdf\", data_train[:,1], \n",
    "            data_test[:,1], data_predict[:,1], \"x_1\", weight_samples=nBNN, \n",
    "            ymaxAbs=.1, ymaxRel=.1, range=[-1.5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbc2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
