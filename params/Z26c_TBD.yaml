# #########
# # General: #
# #########
runs_dir : "/remote/gpu07/huetsch/GenerativeJetting/runs/13d"
run_name : "TBD_AttentionNet_small_CosSchedule1e2_l2_linear_Adam05Beta"
redirect_console : True
# #########
# # Data: #
# #########
data_path : "/remote/gpu07/huetsch/data/Z_2.npy"
data_type: np
preprocess : True
#channels : [0, 4, 8, 9, 10, 12, 13, 14]
#[0, 4, 8, 9, 10, 12, 13, 14]
#dim : 4qs
# ##############
# # Training:  #
# ##############
train: True
log: True
data_split: [0.5, 0.45, 0.05]

optimizer: Adam
lr : 1.e-3
batch_size : 8192
betas : [0.5, 0.99]
use_scheduler: True
lr_scheduler: "CosineAnnealing"
loss_type: "l2"
multiple_t: False
n_epochs : 20000
validate: False
validate_every : 100

sample_periodically: True
sample_every: 4000
sample_every_n_samples: 100000
# #################
# # Architecture: #
# #################
model: TBD

network: "AttentionNet"
n_blocks : 4
intermediate_dim: 64
n_layers: 5
layers_per_block: 8
n_head: 4
trajectory: "linear_trajectory"
encode_t: False
encode_t_dim: 4
encode_t_scale: 10
#dropout: 0.2

# ###################
# # Loading/saving: #
# ###################
warm_start : False
warm_start_path : "/remote/gpu07/huetsch/GenerativeJetting/runs/Diff_4c_5internal_continue90419/model.pt"

# #############
# # Sampling: #
# #############
sample: True
load_best_checkpoint: False
n_samples : 1000000

# #############
# # Plotting: #
# #############
plot : True
#plot_channels : [9, 10, 13, 14]
#plot_deltaR: True
#plot_Deta_Dphi: True


